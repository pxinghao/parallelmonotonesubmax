%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2014 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2014,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage[subsection]{algorithm}
\usepackage{algorithmic}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2014} with
% \usepackage[nohyperref]{icml2014} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2014} 
% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2014}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{dfn}{Definition}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{exmp}[thm]{Example}
\newtheorem{claim}{Claim}

% Commenting system
\newcommand{\Comments}{1}
\newcommand{\note}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
\newcommand{\xinghao}[1]{\note{red}{[XP: #1]}}
\newcommand{\joey}[1]{\note{blue}{[JG: #1]}}
\newcommand{\stef}[1]{\note{green}{[SJ: #1]}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% ---------------------------------------------------------
%% Terminology
\newcommand{\term}[1]{\textbf{#1}}


%% ---------------------------------------------------------
%% Citation/Reference commands
\newcommand{\citecf}[1]{(\cf, \cite{#1})}
\newcommand{\tableref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\listref}[1]{Listing~\ref{#1}}

\newcommand{\eqnref}[1]{Eq.~(\ref{#1})}
\newcommand{\secref}[1]{Sec.~\ref{#1}}
\newcommand{\chapref}[1]{Chapter~\ref{#1}}

\newcommand{\dfnref}[1]{Definition~\ref{#1}}
\newcommand{\thmref}[1]{Thm.~\ref{#1}}
\newcommand{\propref}[1]{Prop.~\ref{#1}}
\newcommand{\lemref}[1]{Lem~\ref{#1}}
\newcommand{\exmpref}[1]{Example~\ref{#1}}
\newcommand{\corref}[1]{Cor.~\ref{#1}}
\newcommand{\algref}[1]{Alg.~\ref{#1}}
\newcommand{\procref}[1]{Proc.~\ref{#1}}
\newcommand{\alglineref}[1]{Line~\ref{#1}}
\newcommand{\probref}[1]{Problem~(\ref{#1})}
\newcommand{\appendref}[1]{Appendix~\ref{#1}}

%% ---------------------------------------------------------
%% Basic Math
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}


%% ---------------------------------------------------------
%% special math functions
\newcommand{\polylog}[2]{\,\mathbf{Li}_{#1}\left( #2 \right)}
\newcommand{\harmonic}[2]{\,\mathbf{h}_{#1}\left( #2 \right)}

%% ---------------------------------------------------------
%% Norms
\newcommand{\Lone}{L_{1}}
\newcommand{\Linf}{L_{\infty}}
\newcommand{\LInfNorm}[1]{\left|\left| #1 \right|\right|_{\infty}}
\newcommand{\LOneNorm}[1]{\left|\left| #1 \right|\right|_1}

\newcommand{\hinge}[1]{\left[  #1 \right]_+}

%% ---------------------------------------------------------
%% Probability notation
\newcommand{\given}{\,|\,}
\newcommand{\stdist}[1]{\mathbf{\pi} \left( #1 \right) }
\newcommand{\Prb}[1]{\mathbf{P} \left( #1 \right) }
\newcommand{\PrbEst}[1]{\mathbf{\tilde{P}} \left( #1 \right) }
\newcommand{\Ent}[1]{\mathbf{H} \left( #1 \right) }
\newcommand{\PiPrb}[1]{\Prb{ #1 } }
\newcommand{\Kern}[1]{K \left( #1 \right) }
\newcommand{\Ex}[1]{\mathbf{E} \left[ #1 \right] }
\newcommand{\Exwrt}[2]{\mathbf{E}_{#1} \left[ #2 \right] }
\newcommand{\Variance}[1]{\mathbf{Var} \left[ #1 \right] }
\newcommand{\Ind}[1]{\mathbf{1}\left[ #1 \right]}
\newcommand{\Bern}[1]{\text{Bern}( #1 ) }

%% ---------------------------------------------------------
%% Set notation
\newcommand{\reals}{\mathbb{R}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\vecspace}{\mathcal{V}}
\newcommand{\Union}{\bigcup}
\newcommand{\Inter}{\bigcap}
\newcommand{\union}{\cup}
\newcommand{\inter}{\cap}
\newcommand{\size}[1]{\left| #1 \right|}


%% ---------------------------------------------------------
%% Complexity
\newcommand{\BigO}[1]{O\hspace{-1pt}\left( #1 \right)}
\newcommand{\BigTheta}[1]{\Theta \left( #1 \right)}
\newcommand{\BigOmega}[1]{\Omega \left( #1 \right)}





% %% ---------------------------------------------------------
% %% Algorithms
% \SetKwFor{ParForAll}{for}{do in parallel}{end}
% \SetKwFunction{Map}{Map}
% \SetKwFunction{Reduce}{Reduce}

% \SetKwInput{Input}{Input}
% \SetKwInput{Output}{Output}
% \SetKwInput{SideEffect}{SideEffect}
% \SetKwInput{Define}{Define}
% \SetKwInput{Global}{Global}
% \SetKwFor{DoWithProbability}{with probability}{}{}
% \SetKwFunction{DPMeansOp}{DPMeansOp}
% \SetKwFunction{DPValidate}{DPValidate}
% \SetKwFunction{OFLValidate}{OFLValidate}
% \SetKwFunction{BPMeansOp}{BPMeansOp}
% \SetKwFunction{BPValidate}{BPValidate}
% \SetKwFunction{NewClusters}{AcceptedClusters}

% \SetKw{WaitUntil}{wait until}

% \SetKwFunction{Mean}{Mean}
% \SetKwFunction{Ref}{Ref}


%% ---------------------------------------------------------
%% Paper specific notation

\newcommand{\seqlz}{Seq-lg}
\newcommand{\mrlz}{MR-lg}
\newcommand{\scclz}{SCC-lg}
\newcommand{\cclz}{CC-lg}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Parallel Lazy Greedy Monotone Submodular Maximization}

\begin{document} 

\twocolumn[
\icmltitle{Parallel Lazy Greedy Monotone Submodular Maximization}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2014
% package.
\icmlauthor{Xinghao Pan}{xinghao@eecs.berkeley.edu}
\icmlauthor{Stefanie Jegelka}{stefje@eecs.berkeley.edu}
\icmlauthor{Joseph Gonzalez}{jegonzal@eecs.berkeley.edu}
\icmlauthor{Michael I. Jordan}{jordan@eecs.berkeley.edu}
\icmladdress{UC Berkeley}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{submodular maximization, big data, parallel, greedy algorithm}

\vskip 0.3in
]

\begin{abstract} 
We parallelize the lazy greedy algorithm for monotone submodular maximization, using concurrency control.
This allows us to achieve parallel speed ups while retaining a $1-1/e$ approximation.
\end{abstract} 

\section{Introduction}
\label{sec:intro}
Submodular problems are important.
Lazy greedy provides a $1-1/e$ approximation.

However, lazy greedy does not scale to large scale problems.
To tackle big datasets, we need to leverage advances in parallel hardware.
The inherently serial nature of lazy greedy poses a challenge to doing so.

In this paper, we use apply concurrency control to parallelize lazy greedy, and propose a scalable algorithm that achieves the same $1-1/e$ approximation.

\section{Related work}
\label{sec:relatedwork}
\cite{badan14} proposed one-shot MapReduce greedy, which provides a weaker approximation guarantee.

\section{Submodularity}
\label{sec:submodular}

\subsection{Lazy greedy algorithm}
\begin{algorithm}[tb]
  \caption{Serial Lazy Greedy}
  \label{alg:seqlz}
\begin{algorithmic}[1]
  \STATE {\bfseries Input:} data $V$, cardinality constraint $k$
  \STATE Initialize $\forall e \in V$, $\rho_e = \infty$.
  \STATE Initialize $S^0 = \emptyset$
  \STATE Push all $(e, \rho_e)$ onto $PQ$.
  \FOR{$i = 0, \dots, k-1$}
    \WHILE{best element not found}
      \STATE $(e, \rho_e) = PQ.head()$
      \STATE $\rho_e \leftarrow F(S^i\cup e) - F(S^i)$
      \STATE $PQ.update((e,\rho_e))$
      \STATE $(e', \rho_{e'}) = PQ.head()$
      \IF{$e == e'$}
        \STATE $PQ.pop()$
        \STATE $S^{i+1} = S^i \cup e$
      \ENDIF
    \ENDWHILE
  \ENDFOR
\end{algorithmic}
\end{algorithm}


\section{Concurrency Control}
\label{sec:concurrencycontrol}

\section{Parallel lazy greedy}
\label{sec:parlazy}

\subsection{MapReduce algorithm}
\xinghao{Descriptions were written late at night, so apologies for the rambling and poor description.}
The MapReduce lazy greedy algorithm, \mrlz{}, is the most straightforward parallelization of \seqlz{}.
The high-level idea is that we can tighten the upper bounds $\rho_e$ on marginal gains without compromising correctness.
\mrlz{} computes more $\rho_e$'s than \seqlz{}, but distributes this expensive work over multiple processors.
\begin{algorithm}[tb]
  \caption{MapReduce Lazy Greedy}
  \label{alg:mrlz}
\begin{algorithmic}[1]
  \STATE {\bfseries Input:} data $V$, cardinality constraint $k$
  \STATE Initialize $\forall e \in V$, $\rho_e = \infty$.
  \STATE Initialize $S^0 = \emptyset$
  \STATE Push all $(e, \rho_e, 0)$ onto $PQ$.
  \FOR{$i = 0, \dots, k-1$}
    \WHILE{best element not found}
      \STATE $T = \emptyset$
      \FOR{$p = 1, \dots, P$}
        \STATE $(e, \rho_e, i_e) = PQ.pop()$
        \STATE $T \leftarrow T \cup e$
      \ENDFOR
      \STATE $\forall e \in T$, in parallel, $\rho_e \leftarrow F(S^i\cup e) - F(S^i)$
      \STATE $\forall e \in T$, serially, $PQ.push((e, \rho_e, i))$
      \STATE $(e, \rho_e, i_e) = PQ.head()$
      \IF{$i_e = i$}
        \STATE $PQ.pop()$
        \STATE $S^{i+1} = S^i \cup e$
      \ENDIF
    \ENDWHILE
  \ENDFOR
\end{algorithmic}
\end{algorithm}



\subsection{Simple concurrency control algorithm}
\mrlz{} imposes expensive coordination barriers.
\scclz{} attempts to address this problem by asynchronous concurrency control.
In addition, \scclz{} tries to conserve computation for submodular functions with sparse dependencies.
In such cases, the marginal gains for some elements may not be affected by the inclusion of new elements into $S$.
\scclz{} identifies opportunities for re-using the computations of $\rho_e$'s.
\begin{algorithm}[tb]
  \caption{Simple CC Lazy Greedy}
  \label{alg:scclz}
\begin{algorithmic}[1]
  \STATE {\bfseries Input:} data $V$, cardinality constraint $k$
  \STATE Initialize $\forall e \in V$, $\rho_e = \infty$.
  \STATE Initialize $S^0 = \emptyset$
  \STATE Initialize $i = 0$
  \STATE Push all $(e, \rho_e, 0)$ onto $Q$, $\widehat{Q}$.
  \FOR{$p = 1, \dots, P$}
    \WHILE{$i < k$}
      \STATE $(e, \rho_e, i_e) = getNextElement()$
      \IF{$dep(e) \cap (S^i \backslash S^{i_e}) \neq \emptyset$}
        \STATE $\rho_e     \leftarrow F(S^{i_e} \cup e) - F(S^{i_e})$
      \ENDIF
      \STATE $commit(e, \rho_e, i_e)$
    \ENDWHILE
  \ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[tb]
  \caption{Simple $getNextElement()$}
  \label{alg:scclz:getnext}
\begin{algorithmic}
  \STATE $lock(\widehat{Q})$
  \STATE $(e, \rho_e, i_e) = \widehat{Q}.pop()$
  \STATE $i_e \leftarrow i$
  \STATE $unlock(\widehat{Q})$
  \STATE \textbf{return} $(e, \rho_e, i_e)$
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[tb]
  \caption{Simple $commit(e, \rho_e, i_e)$}
  \label{alg:scclz:commit}
\begin{algorithmic}
  \STATE $lock(Q)$, $lock(\widehat{Q})$
  \IF{$dep(e) \cap (S^i \backslash S^{i_e}) = \emptyset$}
    \STATE $i_e \leftarrow i$
  \ENDIF
  \STATE $Q.update(e, \rho_e, i_e)$
  \STATE $(e', \rho_{e'}, i_{e'}) = Q.head()$
  \IF {$e' = e$ \AND $i_e = i$}
    \STATE $Q.pop()$
    \STATE $S^{i+1} = S^i \cup e$
    \STATE $i \leftarrow i + 1$
  \ELSE
    \STATE $\widehat{Q}.push((e, \rho_e, i_e))$
  \ENDIF
  \STATE $unlock(Q)$, $unlock(\widehat{Q})$
\end{algorithmic}
\end{algorithm}




\subsection{Concurrency control algorithm}
\cclz{} takes the ideas of \scclz{} a step further.
Instead of explicitly checking static dependencies, \cclz{} computes a lower bound $\widehat\rho_e$ on the marginal gain too.
To make the decision to add an element $e$ to $S$, it suffices to have $\widehat\rho_e \geq \rho_{e'}$ for all other elements $e' \not\in S$.
This allows us to exploit weak (rather than sparse) and conditional (rather than static) dependencies.
\footnote{
Consider the example for set-cover, where $e$ and $e'$ both cover the set $\mathcal{A}$.
Then $e$ and $e'$ are statically dependent on each other, but if $\mathcal{A}$ is covered by some element in $S$, then $e$ and $e'$ are conditionally independent.
}

\xinghao{The \cclz{} approach may turn out to be less efficient than \scclz{} because of the need to compute $\widehat\rho_e$.
We'll need to actually test this with a bunch of functions to know for sure.}
\begin{algorithm}[tb]
  \caption{Concurrency Control Lazy Greedy}
  \label{alg:cclz}
\begin{algorithmic}[1]
  \STATE {\bfseries Input:} data $V$, cardinality constraint $k$
  \STATE Initialize $\forall e \in V$, $\rho_e = \infty$.
  \STATE Initialize $S = \widehat{S} = \emptyset$
  \STATE Push all $(e, \rho_e)$ onto $Q$, $\widehat{Q}$.
  \FOR{$p = 1, \dots, P$}
    \STATE $e = getNextElement()$
    \STATE $\rho_e     \leftarrow F(S\cup e) - F(S)$
    \STATE $\widehat\rho_e \leftarrow F(\widehat{S}\cup e) - F(\widehat{S})$
    \STATE $commit(e, \rho_e, \widehat\rho_e)$
  \ENDFOR
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[tb]
  \caption{$getNextElement()$}
  \label{alg:cclz:getnext}
\begin{algorithmic}
  \STATE $lock(\widehat{Q})$
  \STATE $(e, \rho_e) = \widehat{Q}.pop()$
  \STATE $unlock(\widehat{Q})$
  \STATE $\widehat{S}(e) = 1$
  \STATE \textbf{return} $e$
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[tb]
  \caption{$commit(e, \rho_e, \widehat\rho_e)$}
  \label{alg:cclz:commit}
\begin{algorithmic}
  \STATE $lock(Q)$, $lock(\widehat{Q})$
  \STATE $Q.update(e, \rho_e)$
  \STATE $(e', \rho_{e'}) = Q.head()$
  \IF {$e' = e$}
    \STATE $Q.pop()$
    \STATE $(e', \rho_{e'}) = Q.head()$
    \STATE $Q.push((e, \rho_e))$
  \ENDIF
  \IF {$\widehat\rho_e \geq \rho_{e'}$}
    \STATE $Q.pop()$
    \STATE $S(e) = 1$
  \ELSE
    \STATE $\widehat{Q}.push((e, \rho_e))$
    \STATE $\widehat{S}(e) = 0$
  \ENDIF
  \STATE $unlock(Q)$, $unlock(\widehat{Q})$
\end{algorithmic}
\end{algorithm}





\subsection{Analysis}
All the parallel algorithms, \mrlz{}, \scclz{}, and \cclz{}, are serially equivalent to some lazy greedy algorithm.
To be more precise, the output of the parallel algorithms are equivalent to serial greedy / lazy greedy, but may compute different upper bounds along the way.

As a corollary, the parallel algorithms have a $1-1/e$ approximation.
\section{Evaluation}
\label{sec:evaluation}

\section{Discussions}
\label{sec:discussions}

% Acknowledgements should only appear in the accepted version. 
% \section*{Acknowledgments} 
 


\bibliography{references_arxiv}
\bibliographystyle{icml2014}

\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
